{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248cbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec6cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8cb69f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"Virny\":\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578f2ab",
   "metadata": {},
   "source": [
    "# One Run One Model Interface Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251a923",
   "metadata": {},
   "source": [
    "In this example, we are going to audit 1 model for stability and fairness, visualize metrics, and create an analysis report. We will use `compute_model_metrics_with_config` interface that will conduct the auditing pipeline for this model. For that, we will need to do next steps:\n",
    "\n",
    "* Initialize input variables\n",
    "\n",
    "* Compute subgroup metrics\n",
    "\n",
    "* Make group metrics composition\n",
    "\n",
    "* Create metrics visualizations and an analysis report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606df34d",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9241de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from virny.user_interfaces.metrics_computation_interfaces import compute_model_metrics_with_config\n",
    "from virny.utils.custom_initializers import create_config_obj, read_model_metric_dfs\n",
    "from virny.custom_classes.metrics_visualizer import MetricsVisualizer\n",
    "from virny.custom_classes.metrics_composer import MetricsComposer\n",
    "from virny.custom_classes.base_dataset import BaseDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75699f5f",
   "metadata": {},
   "source": [
    "## Initialize Input Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f6556",
   "metadata": {},
   "source": [
    "Based on the library flow, we need to create 3 input objects for a user interface:\n",
    "\n",
    "* A **dataset class** that is a wrapper above the userâ€™s raw dataset that includes its descriptive attributes like a target column, numerical columns, categorical columns, etc. This class must be inherited from the BaseDataset class, which was created for user convenience.\n",
    "\n",
    "* A **config yaml** that is a file with configuration parameters for different user interfaces for metrics computation.\n",
    "\n",
    "* Finally, a **models config** that is a Python dictionary, where keys are model names and values are initialized models for analysis. This dictionary helps conduct audits of multiple models for one or multiple runs and analyze different types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f57422",
   "metadata": {},
   "source": [
    "### Create a Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed149cd",
   "metadata": {},
   "source": [
    "Based on the BaseDataset class, your **dataset class** should include the following attributes:\n",
    "\n",
    "* **Obligatory attributes**: dataset, target, features, numerical_columns, categorical_columns\n",
    "\n",
    "* **Optional attributes**: X_data, y_data, columns_with_nulls\n",
    "\n",
    "For more details, please refer to the library documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e3d7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompasDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Dataset class for COMPAS dataset that contains sensitive attributes among feature columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_path\n",
    "        Path to a dataset file\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_path: str):\n",
    "        df = pd.read_csv(dataset_path)\n",
    "\n",
    "        int_columns = ['recidivism', 'age', 'age_cat_25 - 45', 'age_cat_Greater than 45',\n",
    "                       'age_cat_Less than 25', 'c_charge_degree_F', 'c_charge_degree_M', 'sex']\n",
    "        int_columns_dct = {col: \"int\" for col in int_columns}\n",
    "        df = df.astype(int_columns_dct)\n",
    "\n",
    "        target = 'recidivism'\n",
    "        numerical_columns = ['age', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count']\n",
    "        categorical_columns = ['race', 'age_cat_25 - 45', 'age_cat_Greater than 45',\n",
    "                               'age_cat_Less than 25', 'c_charge_degree_F', 'c_charge_degree_M', 'sex']\n",
    "        features = numerical_columns + categorical_columns\n",
    "\n",
    "        super().__init__(\n",
    "            pandas_df=df,\n",
    "            features=features,\n",
    "            target=target,\n",
    "            numerical_columns=numerical_columns,\n",
    "            categorical_columns=categorical_columns,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c55c6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   age  juv_fel_count  juv_misd_count  juv_other_count  priors_count\n0   25            0.0       -2.340451              1.0    -15.010999\n1   26            0.0        0.000000              0.0      0.000000\n2   21            0.0        0.000000              0.0      0.000000\n3   29            0.0        0.000000              0.0      6.000000\n4   40            0.0        0.000000              0.0      7.513697",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>juv_fel_count</th>\n      <th>juv_misd_count</th>\n      <th>juv_other_count</th>\n      <th>priors_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25</td>\n      <td>0.0</td>\n      <td>-2.340451</td>\n      <td>1.0</td>\n      <td>-15.010999</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>7.513697</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CompasDataset(dataset_path=os.path.join('virny', 'datasets', 'COMPAS.csv'))\n",
    "dataset.X_data[dataset.X_data.columns[:5]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f15603",
   "metadata": {},
   "source": [
    "### Create a config object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2a2a9",
   "metadata": {},
   "source": [
    "`compute_model_metrics_with_config` interface requires that your **yaml file** includes the following parameters:\n",
    "\n",
    "* **dataset_name**: a name of your dataset; it will be used to name files with metrics.\n",
    "\n",
    "* **test_set_fraction**: the fraction from the whole dataset in the range [0.0 - 1.0] to create a test set.\n",
    "\n",
    "* **bootstrap_fraction**: the fraction from a train set in the range [0.0 - 1.0] to fit models in bootstrap (usually more than 0.5).\n",
    "\n",
    "* **n_estimators**: the number of estimators for bootstrap to compute subgroup variance metrics.\n",
    "\n",
    "* **sensitive_attributes_dct**: a dictionary where keys are sensitive attribute names (including attribute intersections), and values are privileged values for these attributes. Currently, the library supports only intersections among two sensitive attributes. Intersectional attributes must include '&' between sensitive attributes. You do not need to specify privileged values for intersectional groups since they will be derived from privileged values in sensitive_attributes_dct for each separate sensitive attribute in this intersectional pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61860fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join('docs', 'examples')\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'experiment_config.yaml')\n",
    "config_yaml_content = \"\"\"\n",
    "dataset_name: COMPAS\n",
    "test_set_fraction: 0.2\n",
    "bootstrap_fraction: 0.8\n",
    "n_estimators: 100\n",
    "sensitive_attributes_dct: {'sex': 0, 'age': 25, 'race': 'Caucasian', 'sex&race': None}\n",
    "\"\"\"\n",
    "\n",
    "with open(config_yaml_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(config_yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d8f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_config_obj(config_yaml_path=config_yaml_path)\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results',\n",
    "                                     f'{config.dataset_name}_Metrics_{datetime.now(timezone.utc).strftime(\"%Y%m%d__%H%M%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b81d1",
   "metadata": {},
   "source": [
    "### Create a models config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deeecfa",
   "metadata": {},
   "source": [
    "**models_config** is a Python dictionary, where keys are model names and values are initialized models for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b995b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(criterion='gini',\n",
    "                                                     max_depth=20,\n",
    "                                                     max_features=0.6,\n",
    "                                                     min_samples_split=0.1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f445b64a",
   "metadata": {},
   "source": [
    "## Subgroup Metrics Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3530f06",
   "metadata": {},
   "source": [
    "After the variables are input to a user interface, the interface creates a **generic pipeline** based on the input dataset class to hide preprocessing complexity and provide handy attributes and methods for different types of model analysis. Later this generic pipeline is used in subgroup analyzers that compute different sets of metrics. As for now, our library supports **Subgroup Variance Analyzer** and **Subgroup Statistical Bias Analyzer**, but it is easily extensible to any other analyzers. When the variance and bias analyzers complete metrics computation, their metrics are combined, returned in a matrix format, and stored in a file if defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "197eadaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model random_state:  120\n",
      "Baseline X_train shape:  (4222, 12)\n",
      "Baseline X_test shape:  (1056, 12)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 19:10:38 abstract_overall_variance_analyzer.py INFO    : Start classifiers testing by bootstrap\n"
     ]
    },
    {
     "data": {
      "text/plain": "Classifiers testing by bootstrap:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "599f0fa32ef74c04b7aaa68d0086e0a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 19:10:39 abstract_overall_variance_analyzer.py INFO    : Successfully tested classifiers by bootstrap\n",
      "2023-02-05 19:10:42 abstract_overall_variance_analyzer.py INFO    : Successfully computed predict proba metrics\n"
     ]
    }
   ],
   "source": [
    "metrics_df = compute_model_metrics_with_config(models_config['DecisionTreeClassifier'], 'DecisionTreeClassifier', dataset,\n",
    "                                               config, SAVE_RESULTS_DIR_PATH, save_results=True, debug_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8625a",
   "metadata": {},
   "source": [
    "Look at several columns in top rows of computed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bea94683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                 Metric   overall  sex_priv   sex_dis  age_priv   age_dis\n0                  Mean  0.528258  0.603018  0.510248  0.464100  0.531648\n1                   Std  0.093973  0.109636  0.090200  0.079892  0.094717\n2                   IQR  0.117446  0.141692  0.111605  0.102105  0.118256\n3               Entropy  0.000000  0.000000  0.000000  0.000000  0.252574\n4                Jitter  0.159417  0.183520  0.153611  0.172838  0.158708\n5   Per_Sample_Accuracy  0.667992  0.693415  0.661868  0.656604  0.668594\n6       Label_Stability  0.778523  0.740390  0.787709  0.715472  0.781854\n7                   TPR  0.607069  0.440000  0.637931  0.548387  0.611111\n8                   TNR  0.739130  0.838462  0.710112  0.772727  0.737794\n9                   PPV  0.660633  0.611111  0.667526  0.772727  0.654762\n10                  FNR  0.392931  0.560000  0.362069  0.451613  0.388889\n11                  FPR  0.260870  0.161538  0.289888  0.227273  0.262206\n12             Accuracy  0.678977  0.692683  0.675676  0.641509  0.680957\n13                   F1  0.632719  0.511628  0.652393  0.641509  0.632184\n14       Selection-Rate  0.418561  0.263415  0.455934  0.415094  0.418744\n15        Positive-Rate  0.918919  0.720000  0.955665  0.709677  0.933333",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>overall</th>\n      <th>sex_priv</th>\n      <th>sex_dis</th>\n      <th>age_priv</th>\n      <th>age_dis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mean</td>\n      <td>0.528258</td>\n      <td>0.603018</td>\n      <td>0.510248</td>\n      <td>0.464100</td>\n      <td>0.531648</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Std</td>\n      <td>0.093973</td>\n      <td>0.109636</td>\n      <td>0.090200</td>\n      <td>0.079892</td>\n      <td>0.094717</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IQR</td>\n      <td>0.117446</td>\n      <td>0.141692</td>\n      <td>0.111605</td>\n      <td>0.102105</td>\n      <td>0.118256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Entropy</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.252574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jitter</td>\n      <td>0.159417</td>\n      <td>0.183520</td>\n      <td>0.153611</td>\n      <td>0.172838</td>\n      <td>0.158708</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Per_Sample_Accuracy</td>\n      <td>0.667992</td>\n      <td>0.693415</td>\n      <td>0.661868</td>\n      <td>0.656604</td>\n      <td>0.668594</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Label_Stability</td>\n      <td>0.778523</td>\n      <td>0.740390</td>\n      <td>0.787709</td>\n      <td>0.715472</td>\n      <td>0.781854</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>TPR</td>\n      <td>0.607069</td>\n      <td>0.440000</td>\n      <td>0.637931</td>\n      <td>0.548387</td>\n      <td>0.611111</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>TNR</td>\n      <td>0.739130</td>\n      <td>0.838462</td>\n      <td>0.710112</td>\n      <td>0.772727</td>\n      <td>0.737794</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PPV</td>\n      <td>0.660633</td>\n      <td>0.611111</td>\n      <td>0.667526</td>\n      <td>0.772727</td>\n      <td>0.654762</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>FNR</td>\n      <td>0.392931</td>\n      <td>0.560000</td>\n      <td>0.362069</td>\n      <td>0.451613</td>\n      <td>0.388889</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>FPR</td>\n      <td>0.260870</td>\n      <td>0.161538</td>\n      <td>0.289888</td>\n      <td>0.227273</td>\n      <td>0.262206</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Accuracy</td>\n      <td>0.678977</td>\n      <td>0.692683</td>\n      <td>0.675676</td>\n      <td>0.641509</td>\n      <td>0.680957</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>F1</td>\n      <td>0.632719</td>\n      <td>0.511628</td>\n      <td>0.652393</td>\n      <td>0.641509</td>\n      <td>0.632184</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Selection-Rate</td>\n      <td>0.418561</td>\n      <td>0.263415</td>\n      <td>0.455934</td>\n      <td>0.415094</td>\n      <td>0.418744</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Positive-Rate</td>\n      <td>0.918919</td>\n      <td>0.720000</td>\n      <td>0.955665</td>\n      <td>0.709677</td>\n      <td>0.933333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df[metrics_df.columns[:6]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff67e9",
   "metadata": {},
   "source": [
    "## Group Metrics Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c97e2",
   "metadata": {},
   "source": [
    "**Metrics Composer** is responsible for this second stage of the model audit. Currently, it computes our custom group statistical bias and variance metrics, but extending it for new group metrics is very simple. We noticed that more and more group metrics have appeared during the last decade, but most of them are based on the same subgroup metrics. Hence, such a separation of subgroup and group metrics computation allows one to experiment with different combinations of subgroup metrics and avoid subgroup metrics recomputation for a new set of grouped metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f94a20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics_dct = read_model_metric_dfs(SAVE_RESULTS_DIR_PATH, model_names=['DecisionTreeClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04d06cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_composer = MetricsComposer(models_metrics_dct, config.sensitive_attributes_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a23ece",
   "metadata": {},
   "source": [
    "Compute composed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6ace22",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_composed_metrics_df = metrics_composer.compose_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                          Metric       sex       age      race  sex&race  \\\n0             Equalized_Odds_TPR  0.197931  0.062724  0.186038  0.349172   \n1             Equalized_Odds_FPR  0.128349  0.034933  0.120236  0.230252   \n2               Disparate_Impact  1.327313  1.315152  1.187412  1.730978   \n3  Statistical_Parity_Difference  0.235665  0.223656  0.153337  0.417702   \n4                Accuracy_Parity -0.017007  0.039448 -0.007362 -0.029665   \n5          Label_Stability_Ratio  1.063910  1.092782  1.015365  1.083336   \n6                     IQR_Parity -0.030087  0.016152 -0.005684 -0.033944   \n7                     Std_Parity -0.019436  0.014826 -0.005017 -0.023656   \n8                      Std_Ratio  0.822726  1.185571  0.948220  0.790095   \n9                  Jitter_Parity -0.029909 -0.014130 -0.006402 -0.035366   \n\n               Model_Name  \n0  DecisionTreeClassifier  \n1  DecisionTreeClassifier  \n2  DecisionTreeClassifier  \n3  DecisionTreeClassifier  \n4  DecisionTreeClassifier  \n5  DecisionTreeClassifier  \n6  DecisionTreeClassifier  \n7  DecisionTreeClassifier  \n8  DecisionTreeClassifier  \n9  DecisionTreeClassifier  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>race</th>\n      <th>sex&amp;race</th>\n      <th>Model_Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Equalized_Odds_TPR</td>\n      <td>0.197931</td>\n      <td>0.062724</td>\n      <td>0.186038</td>\n      <td>0.349172</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Equalized_Odds_FPR</td>\n      <td>0.128349</td>\n      <td>0.034933</td>\n      <td>0.120236</td>\n      <td>0.230252</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Disparate_Impact</td>\n      <td>1.327313</td>\n      <td>1.315152</td>\n      <td>1.187412</td>\n      <td>1.730978</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Statistical_Parity_Difference</td>\n      <td>0.235665</td>\n      <td>0.223656</td>\n      <td>0.153337</td>\n      <td>0.417702</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Accuracy_Parity</td>\n      <td>-0.017007</td>\n      <td>0.039448</td>\n      <td>-0.007362</td>\n      <td>-0.029665</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Label_Stability_Ratio</td>\n      <td>1.063910</td>\n      <td>1.092782</td>\n      <td>1.015365</td>\n      <td>1.083336</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>IQR_Parity</td>\n      <td>-0.030087</td>\n      <td>0.016152</td>\n      <td>-0.005684</td>\n      <td>-0.033944</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Std_Parity</td>\n      <td>-0.019436</td>\n      <td>0.014826</td>\n      <td>-0.005017</td>\n      <td>-0.023656</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Std_Ratio</td>\n      <td>0.822726</td>\n      <td>1.185571</td>\n      <td>0.948220</td>\n      <td>0.790095</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Jitter_Parity</td>\n      <td>-0.029909</td>\n      <td>-0.014130</td>\n      <td>-0.006402</td>\n      <td>-0.035366</td>\n      <td>DecisionTreeClassifier</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_composed_metrics_df.head(20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "deb45226",
   "metadata": {},
   "source": [
    "## Metrics Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d4cdb",
   "metadata": {},
   "source": [
    "**Metrics Visualizer** provides metrics visualization and reporting functionality. It unifies different preprocessing methods for result metrics and creates various data formats required for visualizations. Hence, users can simply call methods of the Metrics Visualizer class and get custom plots for diverse metrics analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435b9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = MetricsVisualizer(models_metrics_dct, models_composed_metrics_df, config.dataset_name,\n",
    "                               model_names=['DecisionTreeClassifier'],\n",
    "                               sensitive_attributes_dct=config.sensitive_attributes_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5ff61ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-700c5ea7038849069a023253a2ef717c\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-700c5ea7038849069a023253a2ef717c\") {\n      outputDiv = document.getElementById(\"altair-viz-700c5ea7038849069a023253a2ef717c\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 14, \"titleFontSize\": 18}, \"headerRow\": {\"labelAlign\": \"left\", \"labelAngle\": 0, \"labelFontSize\": 14, \"labelPadding\": 10, \"titleFontSize\": 18}}, \"data\": {\"name\": \"data-16219b4152ce0a8377e649d7a3ed1f91\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"model_name\", \"legend\": {\"labelFontSize\": 13, \"title\": \"Model Name\", \"titleFontSize\": 13}, \"scale\": {\"scheme\": \"tableau20\"}, \"type\": \"nominal\"}, \"row\": {\"field\": \"metric\", \"title\": \"Bias Metrics\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": true}, \"field\": \"overall\", \"title\": \"\", \"type\": \"quantitative\"}, \"y\": {\"axis\": null, \"field\": \"model_name\", \"type\": \"nominal\"}}, \"height\": 50, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-16219b4152ce0a8377e649d7a3ed1f91\": [{\"overall\": 0.6789772727272727, \"metric\": \"Accuracy\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.6327193932827736, \"metric\": \"F1\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.6606334841628959, \"metric\": \"PPV\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.918918918918919, \"metric\": \"Positive-Rate\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.4185606060606061, \"metric\": \"Selection-Rate\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.6070686070686071, \"metric\": \"TPR\", \"model_name\": \"DecisionTreeClassifier\"}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.create_overall_metrics_bar_char(\n",
    "    metrics_names=['TPR', 'PPV', 'Accuracy', 'F1', 'Selection-Rate', 'Positive-Rate'],\n",
    "    metrics_title=\"Bias Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-b977dd0dc13d463990210dacff0fce6c\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-b977dd0dc13d463990210dacff0fce6c\") {\n      outputDiv = document.getElementById(\"altair-viz-b977dd0dc13d463990210dacff0fce6c\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 14, \"titleFontSize\": 18}, \"headerRow\": {\"labelAlign\": \"left\", \"labelAngle\": 0, \"labelFontSize\": 14, \"labelPadding\": 10, \"titleFontSize\": 18}}, \"data\": {\"name\": \"data-2bdca5438465147db1f00c21f79ff68c\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"model_name\", \"legend\": {\"labelFontSize\": 13, \"title\": \"Model Name\", \"titleFontSize\": 13}, \"scale\": {\"scheme\": \"tableau20\"}, \"type\": \"nominal\"}, \"row\": {\"field\": \"metric\", \"title\": \"Variance Metrics\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": true}, \"field\": \"overall\", \"title\": \"\", \"type\": \"quantitative\"}, \"y\": {\"axis\": null, \"field\": \"model_name\", \"type\": \"nominal\"}}, \"height\": 50, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-2bdca5438465147db1f00c21f79ff68c\": [{\"overall\": 0.8825543491634812, \"metric\": \"IQR\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.8405827211509027, \"metric\": \"Jitter\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.7785227272727273, \"metric\": \"Label_Stability\", \"model_name\": \"DecisionTreeClassifier\"}, {\"overall\": 0.9060266424497246, \"metric\": \"Std\", \"model_name\": \"DecisionTreeClassifier\"}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.create_overall_metrics_bar_char(\n",
    "    metrics_names=['Label_Stability'],\n",
    "    reversed_metrics_names=['Std', 'IQR', 'Jitter'],\n",
    "    metrics_title=\"Variance Metrics\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
