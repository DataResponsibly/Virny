{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "248cbed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ec6cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8cb69f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"Virny\":\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578f2ab",
   "metadata": {},
   "source": [
    "# Multiple Runs Interface Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251a923",
   "metadata": {},
   "source": [
    "In this example, we are going to audit 4 models for stability and fairness, visualize metrics, and create an analysis report. To get better analysis accuracy, we will use `compute_metrics_multiple_runs` interface that will make multiple runs per model. For that, we will need to do the next steps:\n",
    "\n",
    "* Initialize input variables\n",
    "\n",
    "* Compute subgroup metrics\n",
    "\n",
    "* Make group metrics composition\n",
    "\n",
    "* Create metrics visualizations and an analysis report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606df34d",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a9241de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj, read_model_metric_dfs, create_models_config_from_tuned_params_df\n",
    "from virny.user_interfaces.metrics_computation_interfaces import compute_metrics_multiple_runs\n",
    "from virny.preprocessing.basic_preprocessing import preprocess_dataset\n",
    "from virny.custom_classes.metrics_visualizer import MetricsVisualizer\n",
    "from virny.custom_classes.metrics_composer import MetricsComposer\n",
    "from virny.utils.model_tuning_utils import tune_ML_models\n",
    "from virny.datasets.data_loaders import BaseDataLoader\n",
    "from virny.configs.constants import ReportType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75699f5f",
   "metadata": {},
   "source": [
    "## Initialize Input Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f6556",
   "metadata": {},
   "source": [
    "Based on the library flow, we need to create 3 input objects for a user interface:\n",
    "\n",
    "* A **config yaml** that is a file with configuration parameters for different user interfaces for metrics computation.\n",
    "\n",
    "* A **dataset class** that is a wrapper above the userâ€™s raw dataset that includes its descriptive attributes like a target column, numerical columns, categorical columns, etc. This class must be inherited from the BaseDataset class, which was created for user convenience.\n",
    "\n",
    "* Finally, a **models config** that is a Python dictionary, where keys are model names and values are initialized models for analysis. This dictionary helps conduct audits of multiple models for one or multiple runs and analyze different types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "DATASET_SPLIT_SEED = 42\n",
    "MODELS_TUNING_SEED = 42\n",
    "TEST_SET_FRACTION = 0.2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "models_params_for_tuning = {\n",
    "    'DecisionTreeClassifier': {\n",
    "        'model': DecisionTreeClassifier(random_state=MODELS_TUNING_SEED),\n",
    "        'params': {\n",
    "            # \"max_depth\": [2, 5, 10, 20, 30],\n",
    "            \"max_depth\": [20, 30],\n",
    "            # \"min_samples_split\" : [0.01, 0.02, 0.05, 0.1],\n",
    "            \"min_samples_split\" : [0.1],\n",
    "            # \"max_features\": [0.6, 'sqrt'],\n",
    "            \"max_features\": ['sqrt'],\n",
    "            \"criterion\": [\"gini\", \"entropy\"]\n",
    "        }\n",
    "    },\n",
    "    # 'LogisticRegression': {\n",
    "    #     'model': LogisticRegression(random_state=MODELS_TUNING_SEED),\n",
    "    #     'params': {\n",
    "    #         'penalty': ['l1', 'l2'],\n",
    "    #         'C' : [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    #         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    #         'max_iter': range(50, 251, 50),\n",
    "    #     }\n",
    "    # },\n",
    "    # 'RandomForestClassifier': {\n",
    "    #     'model': RandomForestClassifier(random_state=MODELS_TUNING_SEED),\n",
    "    #     'params': {\n",
    "    #         \"max_depth\": [3, 4, 6, 10],\n",
    "    #         \"min_samples_leaf\": [1, 2, 4],\n",
    "    #         \"n_estimators\": [50, 100, 500, 700],\n",
    "    #         \"max_features\": [0.6, 'auto', 'sqrt']\n",
    "    #     }\n",
    "    # },\n",
    "    # 'XGBClassifier': {\n",
    "    #     'model': XGBClassifier(random_state=MODELS_TUNING_SEED, verbosity=0),\n",
    "    #     'params': {\n",
    "    #         'learning_rate': [0.1],\n",
    "    #         'n_estimators': [100, 200, 300, 500],\n",
    "    #         'max_depth': [3,5,7,10],\n",
    "    #         'lambda':  [1,10,100]\n",
    "    #     }\n",
    "    # }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a config object"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`compute_metrics_multiple_runs` interface requires that your **yaml file** includes the following parameters:\n",
    "\n",
    "* **dataset_name**: a name of your dataset; it will be used to name files with metrics.\n",
    "\n",
    "* **bootstrap_fraction**: the fraction from a train set in the range [0.0 - 1.0] to fit models in bootstrap (usually more than 0.5).\n",
    "\n",
    "* **n_estimators**: the number of estimators for bootstrap to compute subgroup variance metrics.\n",
    "\n",
    "* **runs_seed_lst**: a list of seeds for each run; the number of runs is derived based on the length of this list. For example, if your runs_seed_lst is [100, 200], this means that for the first run, the interface will use 100 seed, and the code logic will increment this seed for each model (101 for the first model in models_config, 102 for the second model, etc.).\n",
    "\n",
    "* **sensitive_attributes_dct**: a dictionary where keys are sensitive attribute names (including attribute intersections), and values are privileged values for these attributes. Currently, the library supports only intersections among two sensitive attributes. Intersectional attributes must include '&' between sensitive attributes. You do not need to specify privileged values for intersectional groups since they will be derived from privileged values in sensitive_attributes_dct for each separate sensitive attribute in this intersectional pair.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join('docs', 'examples')\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'experiment_config.yaml')\n",
    "config_yaml_content = \"\"\"\n",
    "dataset_name: COMPAS_Without_Sensitive_Attributes\n",
    "bootstrap_fraction: 0.8\n",
    "n_estimators: 50  # Better to input the higher number of estimators than 100; this is only for this use case example\n",
    "# runs_seed_lst: [100, 200, 300, 400, 500]\n",
    "runs_seed_lst: [100, 200]\n",
    "sensitive_attributes_dct: {'sex': 0, 'race': 'Caucasian', 'sex&race': None}\n",
    "\"\"\"\n",
    "\n",
    "with open(config_yaml_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(config_yaml_content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "config = create_config_obj(config_yaml_path=config_yaml_path)\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', f'{config.dataset_name}_Metrics_{datetime.now(timezone.utc).strftime(\"%Y%m%d__%H%M%S\")}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "74f57422",
   "metadata": {},
   "source": [
    "### Preprocess the dataset and create a BaseFlowDataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed149cd",
   "metadata": {},
   "source": [
    "Based on the BaseDataset class, your **dataset class** should include the following attributes:\n",
    "\n",
    "* **Obligatory attributes**: dataset, target, features, numerical_columns, categorical_columns\n",
    "\n",
    "* **Optional attributes**: X_data, y_data, columns_with_nulls\n",
    "\n",
    "For more details, please refer to the library documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e3d7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompasWithoutSensitiveAttrsDataset(BaseDataLoader):\n",
    "    \"\"\"\n",
    "    Dataset class for COMPAS dataset that does not contain sensitive attributes among feature columns\n",
    "     to test blind classifiers\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subsample_size\n",
    "        Subsample size to create based on the input dataset\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_path, subsample_size: int = None):\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        if subsample_size:\n",
    "            df = df.sample(subsample_size)\n",
    "\n",
    "        # Initial data types transformation\n",
    "        int_columns = ['recidivism', 'age', 'age_cat_25 - 45', 'age_cat_Greater than 45',\n",
    "                       'age_cat_Less than 25', 'c_charge_degree_F', 'c_charge_degree_M', 'sex']\n",
    "        int_columns_dct = {col: \"int\" for col in int_columns}\n",
    "        df = df.astype(int_columns_dct)\n",
    "\n",
    "        # Define params\n",
    "        target = 'recidivism'\n",
    "        numerical_columns = ['juv_fel_count', 'juv_misd_count', 'juv_other_count','priors_count']\n",
    "        categorical_columns = ['age_cat_25 - 45', 'age_cat_Greater than 45','age_cat_Less than 25',\n",
    "                               'c_charge_degree_F', 'c_charge_degree_M']\n",
    "\n",
    "        super().__init__(\n",
    "            full_df=df,\n",
    "            target=target,\n",
    "            numerical_columns=numerical_columns,\n",
    "            categorical_columns=categorical_columns\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c55c6a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n0            0.0       -2.340451              1.0    -15.010999   \n1            0.0        0.000000              0.0      0.000000   \n2            0.0        0.000000              0.0      0.000000   \n3            0.0        0.000000              0.0      6.000000   \n4            0.0        0.000000              0.0      7.513697   \n\n   age_cat_25 - 45  \n0                1  \n1                1  \n2                0  \n3                1  \n4                1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>juv_fel_count</th>\n      <th>juv_misd_count</th>\n      <th>juv_other_count</th>\n      <th>priors_count</th>\n      <th>age_cat_25 - 45</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-2.340451</td>\n      <td>1.0</td>\n      <td>-15.010999</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>6.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>7.513697</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = CompasWithoutSensitiveAttrsDataset(dataset_path=os.path.join('virny', 'datasets', 'COMPAS.csv'))\n",
    "data_loader.X_data[data_loader.X_data.columns[:5]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical_features', OneHotEncoder(handle_unknown='ignore', sparse=False), data_loader.categorical_columns),\n",
    "    ('numerical_features', StandardScaler(), data_loader.numerical_columns),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "base_flow_dataset = preprocess_dataset(data_loader, column_transformer, TEST_SET_FRACTION, DATASET_SPLIT_SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tune models and create a models config for metrics computation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023/03/19, 01:40:26: Tuning DecisionTreeClassifier...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "2023/03/19, 01:40:26: Tuning for DecisionTreeClassifier is finished [F1 score = 0.6429262328840039, Accuracy = 0.6442550505050505]\n"
     ]
    },
    {
     "data": {
      "text/plain": "                          Dataset_Name              Model_Name  F1_Score  \\\n0  COMPAS_Without_Sensitive_Attributes  DecisionTreeClassifier  0.642926   \n\n   Accuracy_Score                                  Model_Best_Params  \n0        0.644255  {'criterion': 'gini', 'max_depth': 20, 'max_fe...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dataset_Name</th>\n      <th>Model_Name</th>\n      <th>F1_Score</th>\n      <th>Accuracy_Score</th>\n      <th>Model_Best_Params</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COMPAS_Without_Sensitive_Attributes</td>\n      <td>DecisionTreeClassifier</td>\n      <td>0.642926</td>\n      <td>0.644255</td>\n      <td>{'criterion': 'gini', 'max_depth': 20, 'max_fe...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_params_df, models_config = tune_ML_models(models_params_for_tuning, base_flow_dataset, config.dataset_name, n_folds=3)\n",
    "tuned_params_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "now = datetime.now(timezone.utc)\n",
    "date_time_str = now.strftime(\"%Y%m%d__%H%M%S\")\n",
    "tuned_df_path = os.path.join(ROOT_DIR, 'results', 'models_tuning', f'tuning_results_{config.dataset_name}_{date_time_str}.csv')\n",
    "tuned_params_df.to_csv(tuned_df_path, sep=\",\", columns=tuned_params_df.columns, float_format=\"%.4f\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create models_config from the saved tuned_params_df for higher reliability"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DecisionTreeClassifier': DecisionTreeClassifier(max_depth=20, max_features='sqrt', min_samples_split=0.1,\n",
      "                       random_state=42)}\n"
     ]
    }
   ],
   "source": [
    "models_config = create_models_config_from_tuned_params_df(models_params_for_tuning, tuned_df_path)\n",
    "pprint(models_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "f445b64a",
   "metadata": {},
   "source": [
    "## Subgroup Metrics Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3530f06",
   "metadata": {},
   "source": [
    "After the variables are input to a user interface, the interface creates a **generic pipeline** based on the input dataset class to hide preprocessing complexity and provide handy attributes and methods for different types of model analysis. Later this generic pipeline is used in subgroup analyzers that compute different sets of metrics. As for now, our library supports **Subgroup Variance Analyzer** and **Subgroup Statistical Bias Analyzer**, but it is easily extensible to any other analyzers. When the variance and bias analyzers complete metrics computation, their metrics are combined, returned in a matrix format, and stored in a file if defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "197eadaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Multiple runs progress:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b295cebcc864eb8874c93272f93b4e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Analyze models in one run:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bf030ed59704f75ab74c32c607b2026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################  [Model 1 / 1] Analyze DecisionTreeClassifier  ##############################\n",
      "Model seed:  101\n",
      "#################### ERROR with DecisionTreeClassifier ####################\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny/virny/user_interfaces/metrics_computation_interfaces.py\", line 234, in run_metrics_computation\n",
      "    model_metrics_df = compute_model_metrics(base_model=base_model,\n",
      "  File \"/home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny/virny/user_interfaces/metrics_computation_interfaces.py\", line 102, in compute_model_metrics\n",
      "    test_protected_groups = create_test_protected_groups(dataset.X_test, dataset.init_features_df, sensitive_attributes_dct)\n",
      "  File \"/home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny/virny/utils/common_helpers.py\", line 124, in create_test_protected_groups\n",
      "    if check_sensitive_attrs_in_columns(X_test.columns, sensitive_attributes_dct):\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'columns'\n"
     ]
    },
    {
     "data": {
      "text/plain": "Analyze models in one run:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5cbd96d0ba14520905781771f51c082"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############################  [Model 1 / 1] Analyze DecisionTreeClassifier  ##############################\n",
      "Model seed:  201\n",
      "#################### ERROR with DecisionTreeClassifier ####################\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny/virny/user_interfaces/metrics_computation_interfaces.py\", line 234, in run_metrics_computation\n",
      "    model_metrics_df = compute_model_metrics(base_model=base_model,\n",
      "  File \"/home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny/virny/user_interfaces/metrics_computation_interfaces.py\", line 102, in compute_model_metrics\n",
      "    test_protected_groups = create_test_protected_groups(dataset.X_test, dataset.init_features_df, sensitive_attributes_dct)\n",
      "  File \"/home/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny/virny/utils/common_helpers.py\", line 124, in create_test_protected_groups\n",
      "    if check_sensitive_attrs_in_columns(X_test.columns, sensitive_attributes_dct):\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'columns'\n"
     ]
    }
   ],
   "source": [
    "multiple_run_metrics_dct = compute_metrics_multiple_runs(base_flow_dataset, config, models_config, SAVE_RESULTS_DIR_PATH, debug_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8625a",
   "metadata": {},
   "source": [
    "Look at several columns in top rows of computed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bea94683",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DecisionTreeClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m sample_model_metrics_df \u001B[38;5;241m=\u001B[39m \u001B[43mmultiple_run_metrics_dct\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodels_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m      2\u001B[0m sample_model_metrics_df[sample_model_metrics_df\u001B[38;5;241m.\u001B[39mcolumns[:\u001B[38;5;241m6\u001B[39m]]\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m20\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'DecisionTreeClassifier'"
     ]
    }
   ],
   "source": [
    "sample_model_metrics_df = multiple_run_metrics_dct[list(models_config.keys())[0]]\n",
    "sample_model_metrics_df[sample_model_metrics_df.columns[:6]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff67e9",
   "metadata": {},
   "source": [
    "## Group Metrics Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c97e2",
   "metadata": {},
   "source": [
    "**Metrics Composer** is responsible for this second stage of the model audit. Currently, it computes our custom group statistical bias and variance metrics, but extending it for new group metrics is very simple. We noticed that more and more group metrics have appeared during the last decade, but most of them are based on the same subgroup metrics. Hence, such a separation of subgroup and group metrics computation allows one to experiment with different combinations of subgroup metrics and avoid subgroup metrics recomputation for a new set of grouped metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a20dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metrics_dct = read_model_metric_dfs(SAVE_RESULTS_DIR_PATH, model_names=list(models_config.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d06cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_composer = MetricsComposer(models_metrics_dct, config.sensitive_attributes_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a23ece",
   "metadata": {},
   "source": [
    "Compute composed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ace22",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_composed_metrics_df = metrics_composer.compose_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb45226",
   "metadata": {},
   "source": [
    "## Metrics Visualization and Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d4cdb",
   "metadata": {},
   "source": [
    "**Metrics Visualizer** provides metrics visualization and reporting functionality. It unifies different preprocessing methods for result metrics and creates various data formats required for visualizations. Hence, users can simply call methods of the Metrics Visualizer class and get custom plots for diverse metrics analysis. Additionally, these plots could be collected in an HTML report with comments for user convenience and future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = MetricsVisualizer(models_metrics_dct, models_composed_metrics_df, config.dataset_name,\n",
    "                               model_names=list(models_config.keys()),\n",
    "                               sensitive_attributes_dct=config.sensitive_attributes_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec25ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.create_boxes_and_whiskers_for_models_multiple_runs(metrics_lst=['Std', 'IQR', 'Jitter', 'FNR','FPR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.create_overall_metrics_bar_char(\n",
    "    metrics_names=['TPR', 'PPV', 'Accuracy', 'F1', 'Selection-Rate', 'Positive-Rate'],\n",
    "    metrics_title=\"Bias Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.create_overall_metrics_bar_char(\n",
    "    metrics_names=['Label_Stability'],\n",
    "    reversed_metrics_names=['Std', 'IQR', 'Jitter'],\n",
    "    metrics_title=\"Variance Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is an example of an interactive plot. It requires that you run the below cell in Jupyter in the browser or EDAs, which support JavaScript displaying.\n",
    "\n",
    "You can use this plot to compare any pair of bias and variance metrics for all models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualizer.create_bias_variance_interactive_bar_chart()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df024aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.create_model_rank_heatmaps(\n",
    "    metrics_lst=[\n",
    "        # Group statistical bias metrics\n",
    "        'Equalized_Odds_TPR',\n",
    "        'Equalized_Odds_FPR',\n",
    "        'Disparate_Impact',\n",
    "        'Statistical_Parity_Difference',\n",
    "        'Accuracy_Parity',\n",
    "        # Group variance metrics\n",
    "        'Label_Stability_Ratio',\n",
    "        'IQR_Parity',\n",
    "        'Std_Parity',\n",
    "        'Std_Ratio',\n",
    "        'Jitter_Parity',\n",
    "    ],\n",
    "    groups_lst=config.sensitive_attributes_dct.keys(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6ce42",
   "metadata": {},
   "source": [
    "Create an analysis report. It includes correspondent visualizations and details about your result metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3811ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.create_html_report(report_type=ReportType.MULTIPLE_RUNS_MULTIPLE_MODELS,\n",
    "                              report_save_path=os.path.join(ROOT_DIR, \"results\", \"reports\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326c129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
