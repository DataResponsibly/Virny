{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ae1475",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.013441Z",
     "end_time": "2023-04-21T21:00:33.188847Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1a7163",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.046406Z",
     "end_time": "2023-04-21T21:00:33.192071Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd0d321",
   "metadata": {},
   "source": [
    "# Multiple Models Interface For Multiple Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3e85da",
   "metadata": {},
   "source": [
    "In this example, we are going to audit 2 models for stability and fairness, visualize metrics, and create an analysis report. To get better analysis accuracy, we will use `compute_metrics_multiple_runs_with_multiple_test_sets` interface that will run metric computation for multiple models and test each model using multiple test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19ca31",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec1f3f0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.065923Z",
     "end_time": "2023-04-21T21:00:33.203135Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from virny.user_interfaces.metrics_computation_interfaces import compute_metrics_multiple_runs_with_multiple_test_sets\n",
    "from virny.utils.custom_initializers import create_config_obj, create_models_metrics_dct_from_database_df\n",
    "from virny.preprocessing.basic_preprocessing import preprocess_dataset\n",
    "from virny.datasets.data_loaders import CompasWithoutSensitiveAttrsDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d088c",
   "metadata": {},
   "source": [
    "## Initialize Input Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb167839",
   "metadata": {},
   "source": [
    "Based on the library flow, we need to create 3 input objects for a user interface:\n",
    "\n",
    "* A **dataset class** that is a wrapper above the userâ€™s raw dataset that includes its descriptive attributes like a target column, numerical columns, categorical columns, etc. This class must be inherited from the BaseDataset class, which was created for user convenience.\n",
    "\n",
    "* A **config yaml** that is a file with configuration parameters for different user interfaces for metrics computation.\n",
    "\n",
    "* Finally, a **models config** that is a Python dictionary, where keys are model names and values are initialized models for analysis. This dictionary helps conduct audits of multiple models and analyze different types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "TEST_SET_FRACTION = 0.2\n",
    "DATASET_SPLIT_SEED = 42"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.090649Z",
     "end_time": "2023-04-21T21:00:33.209423Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4b21d920",
   "metadata": {},
   "source": [
    "### Create a Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b42644",
   "metadata": {},
   "source": [
    "Based on the BaseDataset class, your **dataset class** should include the following attributes:\n",
    "\n",
    "* **Obligatory attributes**: dataset, target, features, numerical_columns, categorical_columns\n",
    "\n",
    "* **Optional attributes**: X_data, y_data, columns_with_nulls\n",
    "\n",
    "For more details, please refer to the library documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a74059",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.104210Z",
     "end_time": "2023-04-21T21:00:33.248129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n0            0.0       -2.340451              1.0    -15.010999   \n1            0.0        0.000000              0.0      0.000000   \n2            0.0        0.000000              0.0      0.000000   \n3            0.0        0.000000              0.0      6.000000   \n4            0.0        0.000000              0.0      7.513697   \n\n   age_cat_25 - 45  \n0                1  \n1                1  \n2                0  \n3                1  \n4                1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>juv_fel_count</th>\n      <th>juv_misd_count</th>\n      <th>juv_other_count</th>\n      <th>priors_count</th>\n      <th>age_cat_25 - 45</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-2.340451</td>\n      <td>1.0</td>\n      <td>-15.010999</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>6.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>7.513697</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = CompasWithoutSensitiveAttrsDataset()\n",
    "data_loader.X_data[data_loader.X_data.columns[:5]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical_features', OneHotEncoder(handle_unknown='ignore', sparse=False), data_loader.categorical_columns),\n",
    "    ('numerical_features', StandardScaler(), data_loader.numerical_columns),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.178231Z",
     "end_time": "2023-04-21T21:00:33.248529Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "base_flow_dataset = preprocess_dataset(data_loader, column_transformer, TEST_SET_FRACTION, DATASET_SPLIT_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.178397Z",
     "end_time": "2023-04-21T21:00:33.290936Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "d22f31eb",
   "metadata": {},
   "source": [
    "### Create a config object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8dda3",
   "metadata": {},
   "source": [
    "`compute_metrics_multiple_runs_with_multiple_test_sets` interface requires that your **yaml file** includes the following parameters:\n",
    "\n",
    "* **dataset_name**: str, a name of your dataset; it will be used to name files with metrics.\n",
    "\n",
    "* **bootstrap_fraction**: float, the fraction from a train set in the range [0.0 - 1.0] to fit models in bootstrap (usually more than 0.5).\n",
    "\n",
    "* **n_estimators**: int, the number of estimators for bootstrap to compute subgroup variance metrics.\n",
    "\n",
    "* **sensitive_attributes_dct**: dict, a dictionary where keys are sensitive attribute names (including attribute intersections), and values are privileged values for these attributes. Currently, the library supports only intersections among two sensitive attributes. Intersectional attributes must include '&' between sensitive attributes. You do not need to specify privileged values for intersectional groups since they will be derived from privileged values in sensitive_attributes_dct for each separate sensitive attribute in this intersectional pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79dcac74",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.222274Z",
     "end_time": "2023-04-21T21:00:33.298334Z"
    }
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'experiment_config.yaml')\n",
    "config_yaml_content = \\\n",
    "\"\"\"dataset_name: COMPAS_Without_Sensitive_Attributes\n",
    "bootstrap_fraction: 0.8\n",
    "n_estimators: 50  # Better to input the higher number of estimators than 100; this is only for this use case example\n",
    "computation_mode: error_analysis\n",
    "sensitive_attributes_dct: {'sex': 1, 'race': 'African-American', 'sex&race': None}\n",
    "\"\"\"\n",
    "\n",
    "with open(config_yaml_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(config_yaml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc8bd6f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.222617Z",
     "end_time": "2023-04-21T21:00:33.299673Z"
    }
   },
   "outputs": [],
   "source": [
    "config = create_config_obj(config_yaml_path=config_yaml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04867aa",
   "metadata": {},
   "source": [
    "### Create a models config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee85f0",
   "metadata": {},
   "source": [
    "**models_config** is a Python dictionary, where keys are model names and values are initialized models for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a711e1af",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.254072Z",
     "end_time": "2023-04-21T21:00:33.316766Z"
    }
   },
   "outputs": [],
   "source": [
    "models_config = {\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(criterion='gini',\n",
    "                                                     max_depth=20,\n",
    "                                                     max_features=0.6,\n",
    "                                                     min_samples_split=0.1),\n",
    "    'RandomForestClassifier': RandomForestClassifier(max_depth=4,\n",
    "                                                     max_features=0.6,\n",
    "                                                     min_samples_leaf=1,\n",
    "                                                     n_estimators=50),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ba72b",
   "metadata": {},
   "source": [
    "## Subgroup Metrics Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13404bc0",
   "metadata": {},
   "source": [
    "After the variables are input to a user interface, the interface uses subgroup analyzers to compute different sets of metrics for each privileged and disprivileged subgroup. As for now, our library supports **Subgroup Variance Analyzer** and **Subgroup Error Analyzer**, but it is easily extensible to any other analyzers. When the variance and error analyzers complete metrics computation, their metrics are combined, returned in a matrix format, and stored in a file if defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "899e6ab4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.276325Z",
     "end_time": "2023-04-21T21:00:33.347605Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "load_dotenv(os.path.join(ROOT_DIR, 'secrets.env'))  # Take environment variables from .env\n",
    "\n",
    "# Provide the mongodb atlas url to connect python to mongodb using pymongo\n",
    "CONNECTION_STRING = os.getenv(\"CONNECTION_STRING\")\n",
    "# Create a connection using MongoClient. You can import MongoClient or use pymongo.MongoClient\n",
    "client = MongoClient(CONNECTION_STRING)\n",
    "collection = client[os.getenv(\"DB_NAME\")]['preprocessing_results']\n",
    "\n",
    "\n",
    "def db_writer_func(run_models_metrics_df, collection=collection):\n",
    "    run_models_metrics_df.columns = run_models_metrics_df.columns.str.lower()  # Rename Pandas columns to lower case\n",
    "    collection.insert_many(run_models_metrics_df.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db8df420",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.307946Z",
     "end_time": "2023-04-21T21:00:33.374261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current session uuid:  b2945b06-3cbe-4e6f-80f4-8f8b8228b359\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "custom_table_fields_dct = {\n",
    "    'session_uuid': str(uuid.uuid4()),\n",
    "    'preprocessing_techniques': 'one hot encoder and scaler',\n",
    "}\n",
    "print('Current session uuid: ', custom_table_fields_dct['session_uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46961cf7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:00:33.337707Z",
     "end_time": "2023-04-21T21:01:18.861379Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Analyze models in one run:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f91cc2f8c3445769f6bb5485ca87159"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Classifiers testing by bootstrap:   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33053d252db4431eb7ca7f55c9b105ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Classifiers testing by bootstrap:   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa205a99f391414cb4d045cb554efe10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extra_test_sets_lst = [(base_flow_dataset.X_test, base_flow_dataset.y_test)]\n",
    "compute_metrics_multiple_runs_with_multiple_test_sets(base_flow_dataset, extra_test_sets_lst, config, models_config,\n",
    "                                                      custom_table_fields_dct, db_writer_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "180f429c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:01:18.864681Z",
     "end_time": "2023-04-21T21:01:18.906341Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_model_metric_dfs_from_db(collection, session_uuid):\n",
    "    cursor = collection.find({'session_uuid': session_uuid})\n",
    "    records = []\n",
    "    for record in cursor:\n",
    "        del record['_id']\n",
    "        records.append(record)\n",
    "\n",
    "    model_metric_dfs = pd.DataFrame(records)\n",
    "\n",
    "    # Capitalize column names to be consistent across the whole library\n",
    "    new_column_names = []\n",
    "    for col in model_metric_dfs.columns:\n",
    "        new_col_name = '_'.join([c.capitalize() for c in col.split('_')])\n",
    "        new_column_names.append(new_col_name)\n",
    "\n",
    "    model_metric_dfs.columns = new_column_names\n",
    "    return model_metric_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a38bb0",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:01:18.906230Z",
     "end_time": "2023-04-21T21:01:19.217098Z"
    }
   },
   "outputs": [],
   "source": [
    "model_metric_dfs = read_model_metric_dfs_from_db(collection, custom_table_fields_dct['session_uuid'])\n",
    "models_metrics_dct = create_models_metrics_dct_from_database_df(model_metric_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e73354b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:01:19.251155Z",
     "end_time": "2023-04-21T21:01:19.343610Z"
    }
   },
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a94b000c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-21T21:01:19.324534Z",
     "end_time": "2023-04-21T21:01:19.343878Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aeeedfdcfbb7d0bd7e8ae453d9cd04ee7ebd63a67f7841163d9437c8723e8c72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
