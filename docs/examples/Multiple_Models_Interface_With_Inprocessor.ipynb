{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248cbed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:15.669598Z",
     "start_time": "2024-01-29T12:44:15.216009Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec6cd08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:15.679615Z",
     "start_time": "2024-01-29T12:44:15.670057Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8cb69f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:15.689276Z",
     "start_time": "2024-01-29T12:44:15.679903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current location:  /Users/denys_herasymuk/UCU/4course_2term/Bachelor_Thesis/Code/Virny\n"
     ]
    }
   ],
   "source": [
    "cur_folder_name = os.getcwd().split('/')[-1]\n",
    "if cur_folder_name != \"Virny\":\n",
    "    os.chdir(\"../..\")\n",
    "\n",
    "print('Current location: ', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a578f2ab",
   "metadata": {},
   "source": [
    "# Multiple Models Interface With Inprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2251a923",
   "metadata": {},
   "source": [
    "In this example, we are going to audit one inprocessor from AIF360 for stability and fairness, visualize metrics, and create an analysis report. For that, we will use `compute_metrics_with_config` interface that can compute metrics for multiple models. Thus, we will need to do the next steps:\n",
    "\n",
    "* Initialize input variables\n",
    "\n",
    "* Compute subgroup metrics\n",
    "\n",
    "* Make group metrics composition\n",
    "\n",
    "* Create metrics visualizations and an analysis report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606df34d",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a9241de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:16.959157Z",
     "start_time": "2024-01-29T12:44:15.690014Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': LawSchoolGPADataset will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from virny.utils.custom_initializers import create_config_obj, read_model_metric_dfs\n",
    "from virny.user_interfaces.multiple_models_api import compute_metrics_with_config\n",
    "from virny.preprocessing.basic_preprocessing import preprocess_dataset\n",
    "from virny.custom_classes.metrics_visualizer import MetricsVisualizer\n",
    "from virny.custom_classes.metrics_composer import MetricsComposer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75699f5f",
   "metadata": {},
   "source": [
    "## Initialize Input Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f6556",
   "metadata": {},
   "source": [
    "Based on the library flow, we need to create 3 input objects for a user interface:\n",
    "\n",
    "* A **config yaml** that is a file with configuration parameters for different user interfaces for metrics computation.\n",
    "\n",
    "* A **dataset class** that is a wrapper above the userâ€™s raw dataset that includes its descriptive attributes like a target column, numerical columns, categorical columns, etc. This class must be inherited from the BaseDataset class, which was created for user convenience.\n",
    "\n",
    "* Finally, a **models config** that is a Python dictionary, where keys are model names and values are initialized models for analysis. This dictionary helps conduct audits for different analysis modes and analyze different types of models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "DATASET_SPLIT_SEED = 42\n",
    "MODELS_TUNING_SEED = 42\n",
    "TEST_SET_FRACTION = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:16.985255Z",
     "start_time": "2024-01-29T12:44:16.959855Z"
    }
   },
   "id": "ce359a052925eb3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a config object"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1090a686532d96f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`compute_metrics_with_config` interface requires that your **yaml file** includes the following parameters:\n",
    "\n",
    "* **dataset_name**: str, a name of your dataset; it will be used to name files with metrics.\n",
    "\n",
    "* **bootstrap_fraction**: float, the fraction from a train set in the range [0.0 - 1.0] to fit models in bootstrap (usually more than 0.5).\n",
    "\n",
    "* **n_estimators**: int, the number of estimators for bootstrap to compute subgroup stability metrics.\n",
    "\n",
    "* **sensitive_attributes_dct**: dict, a dictionary where keys are sensitive attribute names (including intersectional attributes), and values are disadvantaged values for these attributes. Intersectional attributes must include '&' between sensitive attributes. You do not need to specify disadvantaged values for intersectional groups since they will be derived from disadvantaged values in sensitive_attributes_dct for each separate sensitive attribute in this intersectional pair."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0a03b8f5c5d0ea7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.join('docs', 'examples')\n",
    "config_yaml_path = os.path.join(ROOT_DIR, 'experiment_config.yaml')\n",
    "config_yaml_content = \"\"\"\n",
    "dataset_name: Law_School\n",
    "bootstrap_fraction: 0.8\n",
    "computation_mode: error_analysis\n",
    "n_estimators: 30  # Better to input the higher number of estimators than 100; this is only for this use case example\n",
    "sensitive_attributes_dct: {'male': '0.0', 'race': 'Non-White', 'male&race': None}\n",
    "\"\"\"\n",
    "\n",
    "with open(config_yaml_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(config_yaml_content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:17.009928Z",
     "start_time": "2024-01-29T12:44:16.983539Z"
    }
   },
   "id": "af22ee06f1e3eb1a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "config = create_config_obj(config_yaml_path=config_yaml_path)\n",
    "SAVE_RESULTS_DIR_PATH = os.path.join(ROOT_DIR, 'results', f'{config.dataset_name}_Metrics_{datetime.now(timezone.utc).strftime(\"%Y%m%d__%H%M%S\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:17.028644Z",
     "start_time": "2024-01-29T12:44:17.006813Z"
    }
   },
   "id": "65181f72484bb92b"
  },
  {
   "cell_type": "markdown",
   "id": "74f57422",
   "metadata": {},
   "source": [
    "### Preprocess the dataset and create a BaseFlowDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c55c6a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:17.092758Z",
     "start_time": "2024-01-29T12:44:17.028946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   decile1b  decile3  lsat  ugpa  zfygpa\n0      10.0     10.0  44.0   3.5    1.33\n1       5.0      4.0  29.0   3.5   -0.11\n2       8.0      7.0  37.0   3.4    0.63\n3       8.0      7.0  43.0   3.3    0.67\n4       3.0      2.0  41.0   3.3   -0.67",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>decile1b</th>\n      <th>decile3</th>\n      <th>lsat</th>\n      <th>ugpa</th>\n      <th>zfygpa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>44.0</td>\n      <td>3.5</td>\n      <td>1.33</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>29.0</td>\n      <td>3.5</td>\n      <td>-0.11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>37.0</td>\n      <td>3.4</td>\n      <td>0.63</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8.0</td>\n      <td>7.0</td>\n      <td>43.0</td>\n      <td>3.3</td>\n      <td>0.67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>41.0</td>\n      <td>3.3</td>\n      <td>-0.67</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from virny.datasets import LawSchoolDataset\n",
    "\n",
    "data_loader = LawSchoolDataset()\n",
    "data_loader.X_data[data_loader.X_data.columns[:5]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer(transformers=[\n",
    "    ('categorical_features', OneHotEncoder(handle_unknown='ignore', sparse=False), data_loader.categorical_columns),\n",
    "    ('numerical_features', StandardScaler(), data_loader.numerical_columns),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:17.110916Z",
     "start_time": "2024-01-29T12:44:17.091799Z"
    }
   },
   "id": "ebbef5eaf9dc0943"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Create a binary race column for in-processing since aif360 inprocessors use a sensitive attribute during their learning.\n",
    "data_loader.X_data['race_binary'] = data_loader.X_data['race'].apply(lambda x: 1 if x == 'White' else 0)\n",
    "\n",
    "base_flow_dataset = preprocess_dataset(data_loader=data_loader,\n",
    "                                       column_transformer=column_transformer,\n",
    "                                       sensitive_attributes_dct=config.sensitive_attributes_dct,\n",
    "                                       test_set_fraction=TEST_SET_FRACTION,\n",
    "                                       dataset_split_seed=DATASET_SPLIT_SEED)\n",
    "base_flow_dataset.X_train_val['race_binary'] = data_loader.X_data.loc[base_flow_dataset.X_train_val.index, 'race_binary']\n",
    "base_flow_dataset.X_test['race_binary'] = data_loader.X_data.loc[base_flow_dataset.X_test.index, 'race_binary']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:17.169548Z",
     "start_time": "2024-01-29T12:44:17.111451Z"
    }
   },
   "id": "97ed4609effbf53f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define an inprocessor and create a wrapper for it"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6861288861f3350"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To use inprocessors from AIF360 together with Virny, we need to create a wrapper to use it as a basic model in the _models_config_.\n",
    "\n",
    "A wrapper should include the following methods:\n",
    "* **fit(self, X, y)**: fits an inprocessor based on X and y pandas dataframes. Returns self.\n",
    "* **predict_proba(self, X)**: predicts using the fitted inprocessor based on X features pandas dataframe. Returns probabilities for **ZERO** class. These probabilities will be used by Virny in the downstream metric computation.\n",
    "* **predict(self, X)**: predicts using the fitted inprocessor based on X features pandas dataframe. Returns labels for each sample.\n",
    "* **__copy__(self)** and **__deepcopy__(self, memo)**: methods, which will be used during copy.copy(inprocessor_wrapper) and copy.deepcopy(inprocessor_wrapper). Return a new instance of inprocessor's wrapper.\n",
    "* **get_params(self)**: returns parameters of the wrapper. Alignment with sklearn API."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53de71883f66afd0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from aif360.algorithms.inprocessing import ExponentiatedGradientReduction\n",
    "from virny.custom_classes.base_inprocessing_wrapper import BaseInprocessingWrapper\n",
    "from virny.utils.postprocessing_intervention_utils import construct_binary_label_dataset_from_df\n",
    "\n",
    "\n",
    "class ExpGradientReductionWrapper(BaseInprocessingWrapper):\n",
    "    \"\"\"\n",
    "    A wrapper for fair inprocessors from aif360. The wrapper aligns fit, predict, and predict_proba methods\n",
    "    to be compatible with sklearn models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inprocessor\n",
    "        An initialized inprocessor from aif360.\n",
    "    sensitive_attr_for_intervention\n",
    "        A sensitive attribute name to use in the fairness in-processing intervention.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inprocessor, sensitive_attr_for_intervention):\n",
    "        self.sensitive_attr_for_intervention = sensitive_attr_for_intervention\n",
    "        self.inprocessor = inprocessor\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        train_binary_dataset = construct_binary_label_dataset_from_df(X_sample=X,\n",
    "                                                                      y_sample=y,\n",
    "                                                                      target_column='target',\n",
    "                                                                      sensitive_attribute=self.sensitive_attr_for_intervention)\n",
    "        # Fit an inprocessor\n",
    "        self.inprocessor.fit(train_binary_dataset)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        y_empty = np.zeros(X.shape[0])\n",
    "        test_binary_dataset = construct_binary_label_dataset_from_df(X_sample=X,\n",
    "                                                                     y_sample=y_empty,\n",
    "                                                                     target_column='target',\n",
    "                                                                     sensitive_attribute=self.sensitive_attr_for_intervention)\n",
    "        test_dataset_pred = self.inprocessor.predict(test_binary_dataset)\n",
    "        # Set 1.0 since ExponentiatedGradientReduction can return probabilities slightly higher than 1.0.\n",
    "        # This can cause Infinity values for entropy.\n",
    "        test_dataset_pred.scores[test_dataset_pred.scores > 1.0] = 1.0\n",
    "        # Return 1 - test_dataset_pred.scores since scores are probabilities for label 1, not for label 0\n",
    "        return 1 - test_dataset_pred.scores\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_empty = np.zeros(shape=X.shape[0])\n",
    "        test_binary_dataset = construct_binary_label_dataset_from_df(X_sample=X,\n",
    "                                                                     y_sample=y_empty,\n",
    "                                                                     target_column='target',\n",
    "                                                                     sensitive_attribute=self.sensitive_attr_for_intervention)\n",
    "        test_dataset_pred = self.inprocessor.predict(test_binary_dataset)\n",
    "        return test_dataset_pred.labels\n",
    "\n",
    "    def __copy__(self):\n",
    "        new_inprocessor = copy.copy(self.inprocessor)\n",
    "        return ExpGradientReductionWrapper(inprocessor=new_inprocessor,\n",
    "                                           sensitive_attr_for_intervention=self.sensitive_attr_for_intervention)\n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        new_inprocessor = copy.deepcopy(self.inprocessor)\n",
    "        return ExpGradientReductionWrapper(inprocessor=new_inprocessor,\n",
    "                                           sensitive_attr_for_intervention=self.sensitive_attr_for_intervention)\n",
    "\n",
    "    def get_params(self):\n",
    "        return {'sensitive_attr_for_intervention': self.sensitive_attr_for_intervention}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:29.014997Z",
     "start_time": "2024-01-29T12:44:17.171342Z"
    }
   },
   "id": "4535191384245578"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Define a name of a sensitive attribute for the in-processing intervention.\n",
    "# Note that in the above wrapper, 1 is used as a favorable label, and 0 is used as an unfavorable label.\n",
    "sensitive_attr_for_intervention = 'race_binary'\n",
    "\n",
    "# Define an inprocessor\n",
    "estimator = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "inprocessor = ExponentiatedGradientReduction(estimator=estimator,\n",
    "                                             constraints='DemographicParity',\n",
    "                                             drop_prot_attr=True)\n",
    "\n",
    "models_config = {\n",
    "    'ExponentiatedGradientReduction': ExpGradientReductionWrapper(inprocessor=inprocessor, \n",
    "                                                                  sensitive_attr_for_intervention=sensitive_attr_for_intervention)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:44:29.055048Z",
     "start_time": "2024-01-29T12:44:29.017052Z"
    }
   },
   "id": "bd1ee45da7516769"
  },
  {
   "cell_type": "markdown",
   "id": "f445b64a",
   "metadata": {},
   "source": [
    "## Subgroup Metrics Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3530f06",
   "metadata": {},
   "source": [
    "After the variables are input to a user interface, the interface uses subgroup analyzers to compute different sets of metrics for each privileged and disadvantaged subgroup. As for now, our library supports **Subgroup Variance Analyzer** and **Subgroup Error Analyzer**, but it is easily extensible to any other analyzers. When the variance and error analyzers complete metrics computation, their metrics are combined, returned in a matrix format, and stored in a file if defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "197eadaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.882569Z",
     "start_time": "2024-01-29T12:44:29.055317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Analyze multiple models:   0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f9b8110d29a44729fd00bc1865603f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Classifiers testing by bootstrap:   0%|          | 0/30 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "840eebfe1f0c4d0fb8c2257d4c65a3c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_dct = compute_metrics_with_config(dataset=base_flow_dataset,\n",
    "                                          config=config,\n",
    "                                          models_config=models_config,\n",
    "                                          save_results_dir_path=SAVE_RESULTS_DIR_PATH,\n",
    "                                          notebook_logs_stdout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8625a",
   "metadata": {},
   "source": [
    "Look at several columns in top rows of computed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea94683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.883698Z",
     "start_time": "2024-01-29T12:45:31.315538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   Metric      overall    male_priv  male_priv_correct  \\\n0         Mean_Prediction     0.023388     0.020879           0.014551   \n1     Overall_Uncertainty     0.022109     0.019718           0.013374   \n2   Aleatoric_Uncertainty     0.008804     0.007275           0.005080   \n3        Statistical_Bias     0.098350     0.089518           0.004390   \n4                     IQR     0.010310     0.009667           0.007016   \n5                     Std     0.009641     0.008739           0.005772   \n6   Epistemic_Uncertainty     0.013305     0.012443           0.008294   \n7         Label_Stability     0.987516     0.988232           0.991728   \n8                  Jitter     0.009299     0.008656           0.006096   \n9                     TPR     0.990612     0.991163           1.000000   \n10                    TNR     0.138889     0.133028           1.000000   \n11                    PPV     0.908487     0.918534           1.000000   \n12                    FNR     0.009388     0.008837           0.000000   \n13                    FPR     0.861111     0.866972           0.000000   \n14               Accuracy     0.902163     0.912162           1.000000   \n15                     F1     0.947774     0.953468           1.000000   \n16         Selection-Rate     0.977163     0.979730           0.986574   \n17          Positive-Rate     1.090397     1.079070           1.000000   \n18            Sample_Size  4160.000000  2368.000000        2160.000000   \n\n    male_priv_incorrect     male_dis  \n0              0.086595     0.026703  \n1              0.085599     0.025269  \n2              0.030067     0.010825  \n3              0.973543     0.110021  \n4              0.037194     0.011161  \n5              0.039553     0.010832  \n6              0.055532     0.014444  \n7              0.951923     0.986570  \n8              0.035234     0.010149  \n9              0.000000     0.989861  \n10             0.000000     0.144860  \n11             0.000000     0.895129  \n12             1.000000     0.010139  \n13             1.000000     0.855140  \n14             0.000000     0.888951  \n15             0.000000     0.940114  \n16             0.908654     0.973772  \n17             9.947368     1.105830  \n18           208.000000  1792.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>overall</th>\n      <th>male_priv</th>\n      <th>male_priv_correct</th>\n      <th>male_priv_incorrect</th>\n      <th>male_dis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mean_Prediction</td>\n      <td>0.023388</td>\n      <td>0.020879</td>\n      <td>0.014551</td>\n      <td>0.086595</td>\n      <td>0.026703</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Overall_Uncertainty</td>\n      <td>0.022109</td>\n      <td>0.019718</td>\n      <td>0.013374</td>\n      <td>0.085599</td>\n      <td>0.025269</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aleatoric_Uncertainty</td>\n      <td>0.008804</td>\n      <td>0.007275</td>\n      <td>0.005080</td>\n      <td>0.030067</td>\n      <td>0.010825</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Statistical_Bias</td>\n      <td>0.098350</td>\n      <td>0.089518</td>\n      <td>0.004390</td>\n      <td>0.973543</td>\n      <td>0.110021</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>IQR</td>\n      <td>0.010310</td>\n      <td>0.009667</td>\n      <td>0.007016</td>\n      <td>0.037194</td>\n      <td>0.011161</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Std</td>\n      <td>0.009641</td>\n      <td>0.008739</td>\n      <td>0.005772</td>\n      <td>0.039553</td>\n      <td>0.010832</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Epistemic_Uncertainty</td>\n      <td>0.013305</td>\n      <td>0.012443</td>\n      <td>0.008294</td>\n      <td>0.055532</td>\n      <td>0.014444</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Label_Stability</td>\n      <td>0.987516</td>\n      <td>0.988232</td>\n      <td>0.991728</td>\n      <td>0.951923</td>\n      <td>0.986570</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Jitter</td>\n      <td>0.009299</td>\n      <td>0.008656</td>\n      <td>0.006096</td>\n      <td>0.035234</td>\n      <td>0.010149</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>TPR</td>\n      <td>0.990612</td>\n      <td>0.991163</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.989861</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>TNR</td>\n      <td>0.138889</td>\n      <td>0.133028</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.144860</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>PPV</td>\n      <td>0.908487</td>\n      <td>0.918534</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.895129</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>FNR</td>\n      <td>0.009388</td>\n      <td>0.008837</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.010139</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>FPR</td>\n      <td>0.861111</td>\n      <td>0.866972</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.855140</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Accuracy</td>\n      <td>0.902163</td>\n      <td>0.912162</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.888951</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>F1</td>\n      <td>0.947774</td>\n      <td>0.953468</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.940114</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Selection-Rate</td>\n      <td>0.977163</td>\n      <td>0.979730</td>\n      <td>0.986574</td>\n      <td>0.908654</td>\n      <td>0.973772</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Positive-Rate</td>\n      <td>1.090397</td>\n      <td>1.079070</td>\n      <td>1.000000</td>\n      <td>9.947368</td>\n      <td>1.105830</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Sample_Size</td>\n      <td>4160.000000</td>\n      <td>2368.000000</td>\n      <td>2160.000000</td>\n      <td>208.000000</td>\n      <td>1792.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model_metrics_df = metrics_dct[list(models_config.keys())[0]]\n",
    "sample_model_metrics_df[sample_model_metrics_df.columns[:6]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff67e9",
   "metadata": {},
   "source": [
    "## Group Metrics Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c97e2",
   "metadata": {},
   "source": [
    "**Metrics Composer** is responsible for this second stage of the model audit. Currently, it computes our custom group fairness and stability metrics, but extending it for new group metrics is very simple. We noticed that more and more group metrics have appeared during the last decade, but most of them are based on the same subgroup metrics. Hence, such a separation of subgroup and group metrics computation allows one to experiment with different combinations of subgroup metrics and avoid subgroup metrics recomputation for a new set of grouped metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f94a20dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.883793Z",
     "start_time": "2024-01-29T12:45:31.363730Z"
    }
   },
   "outputs": [],
   "source": [
    "models_metrics_dct = read_model_metric_dfs(SAVE_RESULTS_DIR_PATH, model_names=list(models_config.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b04d06cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.883861Z",
     "start_time": "2024-01-29T12:45:31.401036Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics_composer = MetricsComposer(models_metrics_dct, config.sensitive_attributes_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a23ece",
   "metadata": {},
   "source": [
    "Compute composed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be6ace22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.883916Z",
     "start_time": "2024-01-29T12:45:31.434780Z"
    }
   },
   "outputs": [],
   "source": [
    "models_composed_metrics_df = metrics_composer.compose_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                              Metric      male      race  male&race  \\\n0                Accuracy_Difference -0.023211 -0.180454  -0.160337   \n1   Aleatoric_Uncertainty_Difference  0.003550  0.030174   0.032971   \n2        Aleatoric_Uncertainty_Ratio  1.487968  8.174811   6.327559   \n3   Epistemic_Uncertainty_Difference  0.002002  0.010810   0.015361   \n4        Epistemic_Uncertainty_Ratio  1.160858  1.927304   2.270925   \n5                 Equalized_Odds_FNR  0.001302  0.001559   0.003110   \n6                 Equalized_Odds_FPR -0.011832  0.082345   0.057266   \n7                     IQR_Difference  0.001494  0.018301   0.021933   \n8                  Jitter_Difference  0.001493  0.015634   0.017956   \n9              Label_Stability_Ratio  0.998318  0.979427   0.976888   \n10        Label_Stability_Difference -0.001662 -0.020380  -0.022865   \n11    Overall_Uncertainty_Difference  0.005552  0.040984   0.048332   \n12         Overall_Uncertainty_Ratio  1.281547  3.583619   3.644668   \n13                  Disparate_Impact  1.024800  1.248497   1.215937   \n14     Statistical_Parity_Difference -0.005957 -0.010275  -0.011401   \n15                    Std_Difference  0.002092  0.011726   0.015143   \n16                         Std_Ratio  1.239415  2.493035   2.794353   \n17                Equalized_Odds_TNR  0.011832 -0.082345  -0.057266   \n18                Equalized_Odds_TPR -0.001302 -0.001559  -0.003110   \n\n                        Model_Name  \n0   ExponentiatedGradientReduction  \n1   ExponentiatedGradientReduction  \n2   ExponentiatedGradientReduction  \n3   ExponentiatedGradientReduction  \n4   ExponentiatedGradientReduction  \n5   ExponentiatedGradientReduction  \n6   ExponentiatedGradientReduction  \n7   ExponentiatedGradientReduction  \n8   ExponentiatedGradientReduction  \n9   ExponentiatedGradientReduction  \n10  ExponentiatedGradientReduction  \n11  ExponentiatedGradientReduction  \n12  ExponentiatedGradientReduction  \n13  ExponentiatedGradientReduction  \n14  ExponentiatedGradientReduction  \n15  ExponentiatedGradientReduction  \n16  ExponentiatedGradientReduction  \n17  ExponentiatedGradientReduction  \n18  ExponentiatedGradientReduction  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Metric</th>\n      <th>male</th>\n      <th>race</th>\n      <th>male&amp;race</th>\n      <th>Model_Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Accuracy_Difference</td>\n      <td>-0.023211</td>\n      <td>-0.180454</td>\n      <td>-0.160337</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Aleatoric_Uncertainty_Difference</td>\n      <td>0.003550</td>\n      <td>0.030174</td>\n      <td>0.032971</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Aleatoric_Uncertainty_Ratio</td>\n      <td>1.487968</td>\n      <td>8.174811</td>\n      <td>6.327559</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Epistemic_Uncertainty_Difference</td>\n      <td>0.002002</td>\n      <td>0.010810</td>\n      <td>0.015361</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Epistemic_Uncertainty_Ratio</td>\n      <td>1.160858</td>\n      <td>1.927304</td>\n      <td>2.270925</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Equalized_Odds_FNR</td>\n      <td>0.001302</td>\n      <td>0.001559</td>\n      <td>0.003110</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Equalized_Odds_FPR</td>\n      <td>-0.011832</td>\n      <td>0.082345</td>\n      <td>0.057266</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>IQR_Difference</td>\n      <td>0.001494</td>\n      <td>0.018301</td>\n      <td>0.021933</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Jitter_Difference</td>\n      <td>0.001493</td>\n      <td>0.015634</td>\n      <td>0.017956</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Label_Stability_Ratio</td>\n      <td>0.998318</td>\n      <td>0.979427</td>\n      <td>0.976888</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Label_Stability_Difference</td>\n      <td>-0.001662</td>\n      <td>-0.020380</td>\n      <td>-0.022865</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Overall_Uncertainty_Difference</td>\n      <td>0.005552</td>\n      <td>0.040984</td>\n      <td>0.048332</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Overall_Uncertainty_Ratio</td>\n      <td>1.281547</td>\n      <td>3.583619</td>\n      <td>3.644668</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Disparate_Impact</td>\n      <td>1.024800</td>\n      <td>1.248497</td>\n      <td>1.215937</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Statistical_Parity_Difference</td>\n      <td>-0.005957</td>\n      <td>-0.010275</td>\n      <td>-0.011401</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Std_Difference</td>\n      <td>0.002092</td>\n      <td>0.011726</td>\n      <td>0.015143</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Std_Ratio</td>\n      <td>1.239415</td>\n      <td>2.493035</td>\n      <td>2.794353</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Equalized_Odds_TNR</td>\n      <td>0.011832</td>\n      <td>-0.082345</td>\n      <td>-0.057266</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Equalized_Odds_TPR</td>\n      <td>-0.001302</td>\n      <td>-0.001559</td>\n      <td>-0.003110</td>\n      <td>ExponentiatedGradientReduction</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_composed_metrics_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.884361Z",
     "start_time": "2024-01-29T12:45:31.471867Z"
    }
   },
   "id": "a286da0406c6401d"
  },
  {
   "cell_type": "markdown",
   "id": "deb45226",
   "metadata": {},
   "source": [
    "## Metrics Visualization and Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d4cdb",
   "metadata": {},
   "source": [
    "**Metric Visualizer** allows us to build static visualizations for the computed metrics. It unifies different preprocessing methods for the computed metrics and creates various data formats required for visualizations. Hence, users can simply call methods of the _MetricsVisualizer_ class and get custom plots for diverse metric analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "435b9d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.884430Z",
     "start_time": "2024-01-29T12:45:31.509522Z"
    }
   },
   "outputs": [],
   "source": [
    "visualizer = MetricsVisualizer(models_metrics_dct, models_composed_metrics_df, config.dataset_name,\n",
    "                               model_names=list(models_config.keys()),\n",
    "                               sensitive_attributes_dct=config.sensitive_attributes_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5efb1bf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.884716Z",
     "start_time": "2024-01-29T12:45:31.548828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-88507ce88f374bfc8d4eeffaae67738f\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-88507ce88f374bfc8d4eeffaae67738f\") {\n      outputDiv = document.getElementById(\"altair-viz-88507ce88f374bfc8d4eeffaae67738f\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 20}, \"headerRow\": {\"labelAlign\": \"left\", \"labelAngle\": 0, \"labelFontSize\": 16, \"labelPadding\": 10, \"titleFontSize\": 20}}, \"data\": {\"name\": \"data-8e1abd75ad4d8436dab939cadfc9eb86\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"model_name\", \"legend\": {\"labelFontSize\": 15, \"labelLimit\": 300, \"title\": \"Model Name\", \"titleFontSize\": 15, \"titleLimit\": 300}, \"scale\": {\"scheme\": \"tableau20\"}, \"type\": \"nominal\"}, \"row\": {\"field\": \"metric\", \"sort\": [\"Accuracy\", \"F1\", \"TPR\", \"TNR\", \"PPV\", \"Selection-Rate\"], \"title\": \"Accuracy Metrics\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": true}, \"field\": \"overall\", \"title\": \"\", \"type\": \"quantitative\"}, \"y\": {\"axis\": null, \"field\": \"model_name\", \"type\": \"nominal\"}}, \"height\": 50, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-8e1abd75ad4d8436dab939cadfc9eb86\": [{\"overall\": 0.9021634615384616, \"metric\": \"Accuracy\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.9477736430129604, \"metric\": \"F1\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.9084870848708488, \"metric\": \"PPV\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.9771634615384616, \"metric\": \"Selection-Rate\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.1388888888888889, \"metric\": \"TNR\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.9906115879828328, \"metric\": \"TPR\", \"model_name\": \"ExponentiatedGradientReduction\"}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.create_overall_metrics_bar_char(\n",
    "    metric_names=['Accuracy', 'F1', 'TPR', 'TNR', 'PPV', 'Selection-Rate'],\n",
    "    plot_title=\"Accuracy Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eb8528e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T12:46:36.876749Z",
     "start_time": "2024-01-29T12:46:36.777546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "\n<div id=\"altair-viz-4b9935d05e4044f3b5cfdd1f45c67c9c\"></div>\n<script type=\"text/javascript\">\n  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n  (function(spec, embedOpt){\n    let outputDiv = document.currentScript.previousElementSibling;\n    if (outputDiv.id !== \"altair-viz-4b9935d05e4044f3b5cfdd1f45c67c9c\") {\n      outputDiv = document.getElementById(\"altair-viz-4b9935d05e4044f3b5cfdd1f45c67c9c\");\n    }\n    const paths = {\n      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n    };\n\n    function maybeLoadScript(lib, version) {\n      var key = `${lib.replace(\"-\", \"\")}_version`;\n      return (VEGA_DEBUG[key] == version) ?\n        Promise.resolve(paths[lib]) :\n        new Promise(function(resolve, reject) {\n          var s = document.createElement('script');\n          document.getElementsByTagName(\"head\")[0].appendChild(s);\n          s.async = true;\n          s.onload = () => {\n            VEGA_DEBUG[key] = version;\n            return resolve(paths[lib]);\n          };\n          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n          s.src = paths[lib];\n        });\n    }\n\n    function showError(err) {\n      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n      throw err;\n    }\n\n    function displayChart(vegaEmbed) {\n      vegaEmbed(outputDiv, spec, embedOpt)\n        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n    }\n\n    if(typeof define === \"function\" && define.amd) {\n      requirejs.config({paths});\n      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n    } else {\n      maybeLoadScript(\"vega\", \"5\")\n        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n        .catch(showError)\n        .then(() => displayChart(vegaEmbed));\n    }\n  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 20}, \"headerRow\": {\"labelAlign\": \"left\", \"labelAngle\": 0, \"labelFontSize\": 16, \"labelPadding\": 10, \"titleFontSize\": 20}}, \"data\": {\"name\": \"data-a874bf725903e4febd75fa4668d469cb\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"model_name\", \"legend\": {\"labelFontSize\": 15, \"labelLimit\": 300, \"title\": \"Model Name\", \"titleFontSize\": 15, \"titleLimit\": 300}, \"scale\": {\"scheme\": \"tableau20\"}, \"type\": \"nominal\"}, \"row\": {\"field\": \"metric\", \"sort\": [\"Aleatoric_Uncertainty\", \"Epistemic_Uncertainty\", \"Std\", \"IQR\", \"Jitter\"], \"title\": \"Stability and Uncertainty Metrics\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"grid\": true}, \"field\": \"overall\", \"title\": \"\", \"type\": \"quantitative\"}, \"y\": {\"axis\": null, \"field\": \"model_name\", \"type\": \"nominal\"}}, \"height\": 50, \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-a874bf725903e4febd75fa4668d469cb\": [{\"overall\": 0.008804261223772, \"metric\": \"Aleatoric_Uncertainty\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.0133050928217114, \"metric\": \"Epistemic_Uncertainty\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.0103101389257501, \"metric\": \"IQR\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.0092987400530503, \"metric\": \"Jitter\", \"model_name\": \"ExponentiatedGradientReduction\"}, {\"overall\": 0.009640551539234, \"metric\": \"Std\", \"model_name\": \"ExponentiatedGradientReduction\"}]}}, {\"mode\": \"vega-lite\"});\n</script>",
      "text/plain": "alt.Chart(...)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.create_overall_metrics_bar_char(\n",
    "    metric_names=['Aleatoric_Uncertainty', 'Epistemic_Uncertainty', 'Std', 'IQR', 'Jitter'],\n",
    "    plot_title=\"Stability and Uncertainty Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T12:45:31.885027Z",
     "start_time": "2024-01-29T12:45:31.669893Z"
    }
   },
   "id": "713fe55ec5bf095c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
